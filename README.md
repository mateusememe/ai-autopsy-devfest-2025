# AI Autopsy: Hacking and Debugging Decisions with XAI

This repository contains the official code and presentation materials for the hands-on workshop presented at **GDG Presidente Prudente - DevFest 2025** in .

## About This Workshop

AI models are often "black boxes." They give us predictions but can't explain *why*. This is dangerous‚Äîit can lead to biased, unfair, and untrustworthy systems.

In this workshop, we perform an "autopsy" on a black-box model. We will:
1.  Train a high-performance classifier on the classic **Titanic dataset**.
2.  **Debug its logic** to understand *why* it predicts survival or death.
3.  Use powerful Explainable AI (XAI) techniques **LIME** and **SHAP** to make the model transparent.
4.  Generate powerful visualizations to explain individual predictions and global model behavior.

## üöÄ Get Started (Hands-On)

The easiest way to run the workshop code is by using Google Colab, which runs everything in your browser for free.

Just click the badge below!

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mateusememe/ai-autopsy-devfest-2025/blob/main/ai_autopsy_xai_titanic.ipynb)

## üõ†Ô∏è Technologies & Concepts

* **Python 3**
* **Libraries:** scikit-learn, LightGBM, Pandas
* **XAI Tools:** `lime`, `shap`
* **Dataset:** The Titanic

## Repository Contents

* `ai_autopsy_xai_titanic.ipynb`: The main Google Colab notebook with all the hands-on code.
* `slides/`: A directory containing the workshop presentation slides (e.g., in PDF format).

## About the Speakers


* **Mateus Mendon√ßa Monteiro:** [MSc student and Backend Software Engineer at Luizalabs]
  * **LinkedIn:** `linkedin.com/in/mateus-men`
  * **GitHub:** `github.com/mateusememe`
* **Maria Beatriz Fran√ßa**: [Data Scientist Lead in Vericode]
